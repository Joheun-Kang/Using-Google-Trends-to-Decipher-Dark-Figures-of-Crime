{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pytrends.request import TrendReq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GTkeyword(keywords, counts = 1, sleeptime = 0):\n",
    "    now_min = datetime.datetime.now().min\n",
    "    timenow = datetime.datetime.now().strftime('%Y%m%d%H%M')\n",
    "    delta_min = 0\n",
    "    Rotate = 0\n",
    "    count_min = 0\n",
    "    while count_min != counts:\n",
    "\n",
    "        if delta_min != now_min:\n",
    "            kw_list = [keywords]#input('please input your keywords(seperate with \",\" and max 5 keywords): ').split(',')\n",
    "    \n",
    "            time_start = \"2012-01-01\" #input('please input start time of inquary(20XX-XX-XX): ')\n",
    "            time_end = \"2018-12-31\" #input('please input end time of inquary(20XX-XX-XX): ')\n",
    "            delta = datetime.datetime.strptime(time_end, '%Y-%m-%d') - datetime.datetime.strptime(time_start, '%Y-%m-%d')\n",
    "            #print(\"total interval days between your dates are\", delta.days+1, \"days\")\n",
    "            time_interval = delta.days+1 #eval(input('please input interval of days(1-7, or total interval days):'))\"\n",
    "            region = \"US\" #input('please input your interested region(World, US or US-PA, etc): ')\n",
    "            region_level = \"DMA\"#input('please input your interested region level data(\"CITY\" returns city level data, \"COUNTRY\" returns country level data, \"DMA\" returns Metro level data, \"REGION\" returns Region level data):')\n",
    "            Timezone = \"360\" #input('please input your estimate timezone(PST\tPacific Standard Time (North America):480; MST\tMountain Standard Time (North America): 420; CST\tCentral Standard Time (North America): 360; EST\tEastern Standard Time (North America): 300; AST\tAtlantic Standard Time: 240; GMT\tGreenwich Mean Time: 0) : ')\n",
    "            pytrend = TrendReq(hl= 'en-US', tz = Timezone)\n",
    "            if region == \"world\":\n",
    "                region = ''\n",
    "             \n",
    "            def dateRange(beginDate, endDate):\n",
    "                dates = []\n",
    "                dt = datetime.datetime.strptime(beginDate, \"%Y-%m-%d\")\n",
    "                date = beginDate[:]\n",
    "                while date <= endDate:\n",
    "                    dates.append(date)\n",
    "                    if (date == dt.strftime (\"2004-01-01\")) or (date == dt.strftime (\"2008-01-01\"))\\\n",
    "                    or (date == dt.strftime (\"2012-01-01\")) or (date == dt.strftime (\"2016-01-01\")) \\\n",
    "                    or  (date == dt.strftime (\"2020-01-01\")) or  (date == dt.strftime (\"2024-01-01\")):\n",
    "                        dt = dt + datetime.timedelta(time_interval+1)\n",
    "                        date = dt.strftime(\"%Y-%m-%d\")\n",
    "                    else:\n",
    "                        dt = dt + datetime.timedelta(time_interval)\n",
    "                        date = dt.strftime(\"%Y-%m-%d\")          \n",
    "                return dates\n",
    "             \n",
    "            list_of_dates = []\n",
    "            if __name__ == '__main__':\n",
    "                for date in dateRange(time_start, time_end):\n",
    "                    print (date)\n",
    "                    list_of_dates.append(date)\n",
    "            \n",
    "            timeframeX = time_start + \" \" + time_end\n",
    "            \n",
    "            if len(kw_list) == 1:#wirte titles in the files\n",
    "                    filename = keywords.replace('*', '').replace(\" \",\"_\")[0:6]+\"_\"+ \\\n",
    "                    timeframeX + ' tz=' + Timezone +\" \"+ str(time_interval) + 'days' \\\n",
    "                    + \" \" + region + region_level + str(Rotate) + \"_\" + timenow + '.csv'\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        writer = csv.writer(csvfile, delimiter=',')\n",
    "                        writer.writerow(['DateStart','DateEnd', 'Interval Days', 'GeoName', 'Keyword1_' + kw_list[0]])\n",
    "            elif len(kw_list) == 2:\n",
    "                    filename = keywords.replace('*', '').replace(\" \",\"_\")[0:6]+\"_\"+ \\\n",
    "                    kw_list[1] +\"_\"+ timeframeX + ' tz=' + Timezone +\" \"+ str(time_interval)\\\n",
    "                    + 'days' + \" \" + region + region_level + str(Rotate) + \"_\" + timenow + '.csv'\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        writer = csv.writer(csvfile, delimiter=',')\n",
    "                        writer.writerow(['DateStart','DateEnd', 'Interval Days',\\\n",
    "                                         'GeoName', 'Keyword1_' + kw_list[0], 'Keyword2_' + kw_list[1]])\n",
    "            elif len(kw_list) == 3:\n",
    "                    filename = keywords.replace('*', '').replace(\" \",\"_\")[0:6]+\"_\"+\\\n",
    "                    kw_list[1] +\"_\"+ kw_list[2] +\"_\"+ timeframeX + ' tz=' + Timezone\\\n",
    "                    +\" \"+ str(time_interval) + 'days' + \" \" + region + region_level +\\\n",
    "                    str(Rotate) + \"_\" + timenow + '.csv'\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        writer = csv.writer(csvfile, delimiter=',')\n",
    "                        writer.writerow(['DateStart','DateEnd', 'Interval Days', \\\n",
    "                                         'GeoName', 'Keyword1_' + kw_list[0], 'Keyword2_'\\\n",
    "                                         + kw_list[1], 'Keyword3_' + kw_list[2]])\n",
    "            elif len(kw_list) == 4:\n",
    "                    filename = keywords.replace('*', '').replace(\" \",\"_\")[0:6]+\"_\"+ \\\n",
    "                    kw_list[1] +\"_\"+ kw_list[2] +\"_\"+ kw_list[3] +\"_\"+ timeframeX + \\\n",
    "                    ' tz=' + Timezone + \" \"+ str(time_interval) + 'days' + \" \" + region\\\n",
    "                    + region_level + str(Rotate) + \"_\" + timenow + '.csv'\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        writer = csv.writer(csvfile, delimiter=',')\n",
    "                        writer.writerow(['DateStart','DateEnd', 'Interval Days', 'GeoName',\\\n",
    "                                         'Keyword1_' + kw_list[0], 'Keyword2_' + kw_list[1],\\\n",
    "                                         'Keyword3_' + kw_list[2], 'Keyword4_' + kw_list[3]])\n",
    "            elif len(kw_list) == 5:\n",
    "                    filename = keywords.replace('*', '').replace(\" \",\"_\")[0:6]+\"_\"+ kw_list[1] \\\n",
    "                    +\"_\"+ kw_list[2] +\"_\"+ kw_list[3] +\"_\"+ kw_list[4] +\"_\"+ timeframeX + ' tz='\\\n",
    "                    + Timezone +\" \"+ str(time_interval) + 'days' + \" \" + region + region_level + \\\n",
    "                    str(Rotate) + \"_\" + timenow + '.csv'\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        writer = csv.writer(csvfile, delimiter=',')\n",
    "                        writer.writerow(['DateStart','DateEnd', 'Interval Days', 'GeoName', 'Keyword1_'\\\n",
    "                                         + kw_list[0], 'Keyword2_' + kw_list[1], 'Keyword3_' + kw_list[2],\\\n",
    "                                         'Keyword4_' + kw_list[3], 'Keyword5_' + kw_list[4]])\n",
    "            \n",
    "            \n",
    "            \n",
    "            Rotate += 1\n",
    "            \n",
    "            for i in range(0, len(list_of_dates)-1):\n",
    "                end_of_interval_day_plus_one = datetime.datetime.strptime(list_of_dates[i+1], '%Y-%m-%d')\\\n",
    "                #actual enddate should minus one day more. Turn str() into int()\n",
    "                delta = datetime.timedelta(days=1) \n",
    "                n_days= end_of_interval_day_plus_one - delta  #minus 1 day of end day, to make it the right end date.\n",
    "                end_of_interval_day = n_days.strftime('%Y-%m-%d') #turn int() to str()\n",
    "                timeframeX = list_of_dates[i] + \" \" + end_of_interval_day #Right timeframe\n",
    "                pytrend.build_payload(kw_list, timeframe = timeframeX, geo = region) #main function of pytrend\n",
    "                print(pytrend.interest_by_region(resolution = region_level)) \n",
    "               \n",
    "                #print(pytrend.interest_by_region(resolution = region_level).to_csv(path_or_buf= filename))\n",
    "               \n",
    "                select_df = pd.DataFrame(pytrend.interest_by_region(resolution = region_level)) #grab data    \n",
    "                \n",
    "                # See what this data looks like\n",
    "                '''X = dict(select_df)\n",
    "                print(X)\n",
    "                print(select_df.shape)\n",
    "                print(select_df.columns)\n",
    "                print(select_df.index)\n",
    "                print(select_df.describe())'''\n",
    "                \n",
    "                G = select_df.index #Geoname Column\n",
    "                    \n",
    "                if len(kw_list) == 1:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            if Y1.values[j] != 0:\n",
    "                                writer.writerow([list_of_dates[i], end_of_interval_day, time_interval, text, Y1.values[j]])\n",
    "                            \n",
    "                elif len(kw_list) == 2:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            #print(list_of_dates[i], end_of_interval_day, time_interval, G.values[j], Y1.values[j], Y2.values[j])\n",
    "                            writer.writerow([list_of_dates[i], end_of_interval_day, time_interval,\\\n",
    "                                             text, Y1.values[j], Y2.values[j]])\n",
    "                            \n",
    "                elif len(kw_list) == 3:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    Y3 = select_df[kw_list[2]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            writer.writerow([list_of_dates[i], end_of_interval_day, time_interval,\\\n",
    "                                             text, Y1.values[j], Y2.values[j], Y3.values[j]]) \n",
    "                            \n",
    "                elif len(kw_list) == 4:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    Y3 = select_df[kw_list[2]]\n",
    "                    Y4 = select_df[kw_list[3]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            writer.writerow([list_of_dates[i], end_of_interval_day, time_interval,\\\n",
    "                                             text, Y1.values[j], Y2.values[j], Y3.values[j], Y4.values[j]])\n",
    "            \n",
    "                elif len(kw_list) == 5:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    Y3 = select_df[kw_list[2]]\n",
    "                    Y4 = select_df[kw_list[3]]\n",
    "                    Y5 = select_df[kw_list[4]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            writer.writerow([list_of_dates[i], end_of_interval_day, time_interval,\\\n",
    "                                             text, Y1.values[j], Y2.values[j], Y3.values[j], Y4.values[j], Y5.values[j]])\n",
    "                time.sleep(00)   \n",
    "            \n",
    "            \n",
    "            if list_of_dates[-1] != time_end or (list_of_dates[-1] == time_end and time_interval == 1):\n",
    "                timeframeX = list_of_dates[-1]+\" \"+time_end\n",
    "                X1 = datetime.datetime.strptime(list_of_dates[-1], \"%Y-%m-%d\")\n",
    "                X2 = datetime.datetime.strptime(time_end, \"%Y-%m-%d\")\n",
    "                last_interval_of_days = (X2-X1).days + 1\n",
    "                pytrend.build_payload(kw_list, timeframe = timeframeX, geo = region)\n",
    "                print(pytrend.interest_by_region(resolution = region_level))\n",
    "                select_df = pd.DataFrame(pytrend.interest_by_region(resolution = region_level))\n",
    "                G = select_df.index\n",
    "                \n",
    "                if len(kw_list) == 1:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            if Y1.values[j] != 0:\n",
    "                                writer.writerow([list_of_dates[-1], time_end, last_interval_of_days, text, Y1.values[j]])\n",
    "                            \n",
    "                elif len(kw_list) == 2:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            #print(list_of_dates[-1], time_end, last_interval_of_days, G.values[j], Y1.values[j], Y2.values[j])\n",
    "                            writer.writerow([list_of_dates[-1], time_end, last_interval_of_days,\\\n",
    "                                             text, Y1.values[j], Y2.values[j]])\n",
    "                            \n",
    "                elif len(kw_list) == 3:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    Y3 = select_df[kw_list[2]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            writer.writerow([list_of_dates[-1], time_end, last_interval_of_days, \\\n",
    "                                             text, Y1.values[j], Y2.values[j], Y3.values[j]]) \n",
    "                            \n",
    "                elif len(kw_list) == 4:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    Y3 = select_df[kw_list[2]]\n",
    "                    Y4 = select_df[kw_list[3]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            writer.writerow([list_of_dates[-1], time_end, last_interval_of_days,\\\n",
    "                                             text, Y1.values[j], Y2.values[j], Y3.values[j], Y4.values[j]])\n",
    "            \n",
    "                elif len(kw_list) == 5:\n",
    "                    Y1 = select_df[kw_list[0]]\n",
    "                    Y2 = select_df[kw_list[1]]\n",
    "                    Y3 = select_df[kw_list[2]]\n",
    "                    Y4 = select_df[kw_list[3]]\n",
    "                    Y5 = select_df[kw_list[4]]\n",
    "                    with open(filename, 'a+', newline='') as csvfile:\n",
    "                        for j in range (0, len(G.values)):\n",
    "                            writer = csv.writer(csvfile, delimiter=',')\n",
    "                            text = G.values[j]\n",
    "                            writer.writerow([list_of_dates[-1], time_end, last_interval_of_days, \\\n",
    "                                             text, Y1.values[j], Y2.values[j], Y3.values[j], Y4.values[j], Y5.values[j]]) \n",
    "        count_min += 1\n",
    "        delta_min == now_min\n",
    "        time.sleep(sleeptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Motor_Vehicle_Theft_Keywords = \"my car * stolen+bus stolen+truck stolen+report * stolen car+find stolen car\"\n",
    "Burglary_Keywords = \"my * stolen+burglary-car-turck-bus\"\n",
    "Rape_Keywords = \"I * raped+someone raped me+rape report police+my * raped me+being raped+been raped\"\n",
    "\n",
    "listkeywords = [Motor_Vehicle_Theft_Keywords, Burglary_Keywords, Rape_Keywords]\n",
    "repeat = 10\n",
    "sleep = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderlist = []\n",
    "filenamelist = []\n",
    "for i in listkeywords:\n",
    "    #GTkeyword(i, repeat, sleep)\n",
    "    x = i[0:10].replace(\"*\", \"\").replace(\" \",\"_\")\n",
    "    y = time.strftime(\"%Y%m%d\")\n",
    "    z = (x+y)\n",
    "    t = x+\"*.csv\"\n",
    "    folderlist.append(z)\n",
    "    filenamelist.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(filenamelist,folderlist):\n",
    "    !mkdir $j\n",
    "    !move $i $j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file totalfiles already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA0_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA0_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA10_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA10_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA11_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA11_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA12_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA12_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA13_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA13_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA14_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA14_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA15_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA16_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA17_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA18_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA19_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA1_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA1_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA20_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA21_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA22_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA23_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA24_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA25_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA26_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA27_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA28_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA29_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA2_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA2_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA30_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA31_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA32_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA33_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA34_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA35_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA36_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA37_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA38_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA39_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA3_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA3_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA40_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA41_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA42_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA43_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA44_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA45_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA46_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA47_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA48_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA49_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA4_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA4_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA50_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA51_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA52_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA53_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA54_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA55_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA56_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA57_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA58_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA59_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA5_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA5_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA60_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA61_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA62_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA63_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA64_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA65_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA66_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA67_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA68_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA69_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA6_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA6_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA70_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA71_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA72_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA73_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA74_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA75_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA76_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA77_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA78_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA79_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA7_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA7_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA8_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA8_201911232116.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA9_201911230118.csv', 'my_car_2012-01-01 2018-12-31 tz=360 2557days USDMA9_201911232116.csv']\n",
      "['my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA0_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA10_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA11_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA12_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA13_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA14_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA15_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA16_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA17_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA18_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA19_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA1_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA20_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA21_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA22_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA23_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA24_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA25_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA26_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA27_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA28_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA29_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA2_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA30_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA31_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA32_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA33_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA34_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA35_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA36_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA37_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA38_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA39_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA3_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA40_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA41_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA42_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA43_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA44_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA45_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA46_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA47_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA48_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA49_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA4_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA50_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA51_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA52_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA53_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA54_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA55_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA56_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA57_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA58_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA59_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA5_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA60_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA61_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA62_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA63_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA64_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA65_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA66_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA67_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA68_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA69_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA6_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA70_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA71_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA72_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA73_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA74_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA75_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA76_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA77_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA78_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA79_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA7_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA80_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA81_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA82_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA83_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA84_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA85_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA86_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA87_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA88_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA89_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA8_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA90_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA91_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA92_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA93_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA94_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA95_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA96_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA97_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA98_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA99_201911240033.csv', 'my__st_2012-01-01 2018-12-31 tz=360 2557days USDMA9_201911240033.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA0_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA10_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA11_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA12_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA13_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA14_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA15_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA16_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA17_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA18_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA19_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA1_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA20_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA21_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA22_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA23_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA24_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA25_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA26_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA27_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA28_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA29_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA2_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA30_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA31_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA32_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA33_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA34_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA35_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA36_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA37_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA38_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA39_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA3_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA40_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA41_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA42_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA43_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA44_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA45_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA46_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA47_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA48_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA49_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA4_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA50_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA51_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA52_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA53_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA54_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA55_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA56_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA57_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA58_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA59_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA5_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA60_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA61_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA62_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA63_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA64_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA65_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA66_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA67_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA68_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA69_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA6_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA70_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA71_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA72_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA73_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA74_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA75_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA76_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA77_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA78_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA79_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA7_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA80_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA81_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA82_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA83_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA84_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA85_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA86_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA87_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA88_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA89_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA8_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA90_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA91_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA92_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA93_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA94_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA95_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA96_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA97_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA98_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA99_201911240034.csv', 'I__rap_2012-01-01 2018-12-31 tz=360 2557days USDMA9_201911240034.csv']\n"
     ]
    }
   ],
   "source": [
    "!mkdir totalfiles\n",
    "#!del .ipynb_checkpoints \n",
    "for i,j in zip(listkeywords,folderlist):\n",
    "    \n",
    "\n",
    "    route = j+r\"//\"\n",
    "    route2 = \"totalfiles\"+r\"/\"+j+r\"total.csv\"\n",
    "    name_list = os.listdir(route) \n",
    "    if \".ipynb_checkpoints\" in name_list:\n",
    "        name_list.remove(\".ipynb_checkpoints\")\n",
    "    if \"desktop.ini\" in name_list:\n",
    "        name_list.remove(\"desktop.ini\")\n",
    "    print(name_list)\n",
    "    data=[] \n",
    "    df=route + name_list[0]\n",
    "    #print(df)\n",
    "    for k in range(len(name_list)):\n",
    "        #print(k)\n",
    "        #print(name_list)\n",
    "        \n",
    "        df = pd.read_csv(route + name_list[k])\n",
    "        \n",
    "        #print(df)\n",
    "        data.append(df)\n",
    "        #print(data)\n",
    "    data=pd.concat(data)\n",
    "    db1 = data[\"Keyword1_\"+i].groupby(df['GeoName'])\n",
    "    db1.mean().to_csv(route2, index=1,header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
